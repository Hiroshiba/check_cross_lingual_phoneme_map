
（これは音声認識の結果なので、認識結果が誤っている可能性があります。）

クロスリンガルTTSを作るために、まず音素について詳しく知りたいと思っています。日本語と英語の音素です。やりたいことは日本語の音素のうち、英語の音素が色々あるんですけれども、それを日本語で補完することがどれぐらい難しいかを測りたくて、一番測りたいのは、どの音素が難しそうなのかみたいなのを可視化したいですね。どの音素が簡単でどの音素が難しいか、補完が、みたいなのを可視化したいです。

パンフォン、PANPHONを使えば、各音素、IPA音声記号かな。IPA音声記号に対して、IPA音声記号とXサンパは全く一緒なんですけど、それに対してどういう特徴があるかを21次元あるいは22次元くらいで特徴量にマッピングできるものがあるんですね。それを使って音素間の距離を測るのが良さそうであると。

次、日本語のカタカナからIPA音声記号、あるいはXサンパかな。IPA音声記号はちょっと扱いづらいので、Xサンパを出力するためのツールとしてエピトランというのがある。E P I T R A N、エピトランですね。これを使って日本語のカタカナからXサンパ列を生成することができます。

最終的に英語TTSで使うのがアルパベット、A R P A B E T、アルパベットなので、それの音素列も取ってきて、距離関数を測りたいですね。どの音、どの音が、日本語において、多分、表を作るのがいいかなと。どれぐらいの距離で、一番近いのはCと言えばこれ、みたいなのを表にするのがいいかなと思っています。2次元の表にして、日本語と英語の記号を2次元にして、それらの距離を色で把握して、みたいなのとか、あとは日本語に対して、一番近い音はこれ、っていうのを、1かける日本語音素列で表にして、その距離と、一番近い音がどれなのかが分かるようにとか。日本語音素に対してもやるし、英語の音素に対してもやるし、みたいな。3つ表を作ればいいんじゃないかな、とちょっと思っています。

やらなければいけないのが、あと英語の全音素、音声記号もちょっと欲しいですね。アルパベットに対してもできるし、英語の音声記号列に対してもできる、みたいなのも選べると嬉しいかもですね。どっちがいいか分からないですけど。まずやらないといけないのが、エピトランに対して日本語の音素列と、英語のアルパベットの音素列と、英語の音素を取得しないといけないですね。そこから全部が始まるかなと思っているので、それができるかどうかを一番最初にチェックしないといけないかな、と思っています。

文脈として ↓ にも目を通してください。
`C:\Users\hihok\Github\tasks\英語TTS\日本語音素のIPA変換メモ.md`

epitranとpanphonとmatplotlibとseabornとnumpyとscipyとgradioはuvで追加済です。

panphonのドキュメントはこちらです。必要そうであれば目を通してください。
../panphon/ ディレクトリの README.md と README.rst ファイル。２ファイルに書かれているものは異なります。

Epitranのドキュメントはこちらです。必要そうであれば目を通してください。
../epitran/ ディレクトリの README.md ファイル。

まずepitranの`jpn‑Kana`を試します。
`check_epitran_jpn.py`を作り、とりあえず対応する全カタカナをepitranかpanphonから取得してみてください。
取得できるかわかりません。ドキュメントや元コードを追ってください。

X-SAMPAで湧いてきた文字列のどれがどのカタカナから湧いてきているのかって対応関係取れるんですか？
適当にアライメントするのはダメで、エピトランの中身でその仕組みがあるかどうかを聞いてます。
実際に、入力された適当なカタカナ列と、出力されたX-SAMPAとその対応関係みたいなのを取るソースコードを書いてみてください。
その過程の処理もなるべく分析できるようなコードにしてほしいです。
`check_kana.py`というファイル名で作成してください。

`check_kana.py`と同じように、英単語からARPABET列にして、それをさらにX-SAMPAに変換するコードを書いてください。
内部の処理過程もなるべく分析できるコードにしてください。
なるべく自前実装は避け、epitranのコードを利用するようにしてください。マッピングなども模倣せず、なるべく既存関数などを使うのが望ましいです。
ストレス情報は消えてOKです。日本語でも消えるし、英語TTSではストレス情報を別で与えるので。
`check_eitango.py`というファイル名で作成してください。

`check_kana.py`と`check_eitango.py`で、`--all`を指定したときに表示される物がぜんぜん違うんですよね。
英語の方は入力したものと全然関係ないものがいっぱい出てきてます。
他にも言語が違う・arpabetを経由する以外の差が結構あるので、同じようにしてください。

調査をお願いします。
epitranは設計思想として、pre/main/postの変換csvがあれば（なくても良い）、自作の変換も可能ですか？
変換だけあれば動く設計になっているのか、専用コードがあるのかが知りたいです。
例えば言語ごとの特殊処理はありませんか？
また、panphon内にない変換ファイルを指定してそれで変換するとかってできるように作られていますか？
例えば既存のcsvをちょっと変えて使いたいとか簡単にできるようになっていますか。

では実際に実装して使ってみてください。
今回はjpn-kanaと同じcsvファイルを使い、結果が同じになることを確認してください。
このcsvはpreはないですがmainとpostがあるので、それを指定すると良いと思います。
`.venv`以下にそのファイルもあるはずです。それを探して指定しましょう。
check_custom_epitran.pyというファイル名を作成し、テスト結果を表示してください。

調査をお願いします。
メモに書いている通り、無声を考慮したり、`エイ`→`エエ`の写像をやめたりしたいです。
openjtalkの音素ラベルを持っているので、そこから写像するのが良さそうです。
問題はepitranにラベル列を入力しても大丈夫なのかどうかがわからない点です。
openjtalkのラベルはNとn、kとkyとy、clとchのように2文字で1音素を示していたり、他の音素ラベルに近いものがあったりします。
その状況でも正しく音素を写像できるcsvを作れるのかどうか、考えてみてほしいです。
音素の一覧は ../voicevox_engine ディレクトリの voicevox_engine/tts_pipeline/mora_mapping.py にあります。
`_mora_list_additional`の考慮は不要です。
日本語として正しい音素列（無声ラベル含む）がスペース区切りじゃなく存在するとき、必ず正しいIPA音声記号に変換できるようなcsvを作ることができるかどうかを考えてください。

pauは来ない想定にしましょう。
EpitranのARPABET→IPA変換の実装も参考になりそうです。
調査結果を`reports/2025-12-30 openjtalk音素ラベルからIPAへの変換.md`にまとめてください。

---

以上がこれまでの経緯です。
今回は以下のタスクを遂行してください。

続いて実際にopenjtalkのラベルからIPA音声記号・X-SAMPA・panphon特徴量への変換を実装していきましょう。
とりあえずまずは日本語テキストを受け取って音素ラベル列にするコードを書いてください。

次にmora_mapping.pyとKanaのcsvファイルから、モーラを形成する音素ラベル→IPAの変換マップを作ってください。無声化されたシだったら変換元はshIですね。それらのファイルをimportしたり読み込んだりしてcsvを作るコードを`./make_openjtalk_ipa_map.py`に書いて、実行してください。コードをコピーしたりするのは禁止です。`_mora_list_additional`の無視も忘れずにお願いします。
作るcsvは、ヴァ行の子音はIPA音声記号`v`系にしてください。つまり ヴァ,va ヴィ,vi ヴ,vɯ ヴェ,ve ヴォ,voで上書きしてください。
保存先は hiho_data/openjtalk_to_ipa.csv としてください 

まずは言われたところまででお願いします。
前コード書いた人が目的を勘違いしていろいろ書いてる可能性がありますが、破壊的に変えてしまっても問題ありません。

適当にコードを書き換えるのはとても危険です。
自作コードを適当に書くのも理解が浅い場合に危険なので、問題ないのであればライブラリ内の関数を使うようにしてください。
ドキュメントを必ず読んでからタスクを遂行してください。

作業していておかしいと思ったポイントがあったら聞いて下さい。
私もすべてを把握しているわけではないので、変な指示をしている可能性もあります。
